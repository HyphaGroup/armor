# DISARM Framework Reference

**Source:** DISARM Foundation  
**Website:** https://www.disarm.foundation/framework  
**Navigator:** https://disarmfoundation.github.io/disarm-navigator/

---

## Overview

DISARM (originally AMITT - Adversarial Misinformation and Influence Tactics and Techniques) is a framework for analyzing and countering disinformation and influence operations. It provides standardized language for describing information operation tactics and techniques, similar to how MITRE ATT&CK does for cyber attacks.

---

## Framework Structure

### DISARM Red Framework
Documents the behaviors and techniques of those **creating** disinformation/influence operations.

### DISARM Blue Framework
Documents **defensive** actions and countermeasures against disinformation operations.

---

## DISARM Red: Phases and Tactics

Influence operations follow a lifecycle similar to cyber attacks:

### Phase 1: Plan

**Purpose:** Research targets, develop strategy, prepare resources.

| Tactic | Description |
|--------|-------------|
| **Plan Strategy** | Determine operational goals and approach |
| **Plan Objectives** | Define specific targets and outcomes |

### Phase 2: Prepare

**Purpose:** Build capabilities and assets needed for the operation.

| Tactic | Description |
|--------|-------------|
| **Develop Narratives** | Create stories, themes, and messaging |
| **Develop Content** | Produce text, images, video, memes |
| **Establish Legitimacy** | Build credible-seeming personas and platforms |
| **Establish Social Assets** | Create or compromise social media accounts |
| **Build Network** | Develop relationships and amplification capacity |
| **Microtarget** | Identify specific audiences and their vulnerabilities |

### Phase 3: Execute

**Purpose:** Deploy content and run the operation.

| Tactic | Description |
|--------|-------------|
| **Select Channels** | Choose platforms and distribution methods |
| **Deliver Content** | Post, share, and distribute content |
| **Maximize Exposure** | Amplify content reach through various means |
| **Drive Offline Activity** | Convert online influence to real-world action |

### Phase 4: Assess

**Purpose:** Measure impact and refine approach.

| Tactic | Description |
|--------|-------------|
| **Assess Effectiveness** | Measure reach, engagement, impact |
| **Adjust Tactics** | Modify approach based on results |

---

## Key Techniques Relevant to Civil Society

### Content and Narrative Techniques

| Technique | Description | Example |
|-----------|-------------|---------|
| **Develop Competing Narratives** | Create counter-stories | False claims about org's funding, motives |
| **Distort Facts** | Misrepresent true information | Taking quotes out of context |
| **Create Fake Research** | Fabricate studies/data | Fake polls showing opposition to your cause |
| **Develop Conspiracy Narratives** | Complex false explanations | Claims org is "foreign agent" |
| **Appeal to Emotion** | Trigger fear, anger, disgust | Inflammatory framing of your work |

### Persona and Account Techniques

| Technique | Description | Example |
|-----------|-------------|---------|
| **Create Inauthentic Accounts** | Fake social media personas | Accounts posing as supporters-turned-critics |
| **Compromise Legitimate Accounts** | Hack real accounts | Taking over staff accounts |
| **Create Sockpuppets** | Multiple fake personas | Coordinated fake "grassroots" opposition |
| **Impersonate Existing Entity** | Pose as real org/person | Fake accounts using your logo/name |

### Amplification Techniques

| Technique | Description | Example |
|-----------|-------------|---------|
| **Coordinated Inauthentic Behavior** | Organized fake engagement | Bot networks amplifying attacks |
| **Infiltrate Existing Networks** | Join real communities | Agents joining your supporter groups |
| **Cross-posting** | Spread across platforms | Same attack on Twitter, Facebook, forums |
| **Incentivize Sharing** | Motivate organic spread | Contests, paid sharing, tribal appeals |
| **Manipulate Platform Algorithms** | Game recommendation systems | SEO poisoning, trending manipulation |

### Targeting and Harassment Techniques

| Technique | Description | Example |
|-----------|-------------|---------|
| **Identify Targets** | Research individuals | Mapping staff, finding vulnerabilities |
| **Dox** | Reveal private information | Publishing home addresses |
| **Harass** | Targeted abuse | Coordinated pile-ons, threats |
| **Intimidate** | Create fear | Threats implying physical danger |
| **Discredit** | Attack credibility | Accusations of bias, corruption |

### Document and Evidence Techniques

| Technique | Description | Example |
|-----------|-------------|---------|
| **Leak Information** | Strategic document release | Hacked emails released selectively |
| **Create Fake Documents** | Fabricate evidence | Forged internal memos |
| **Selective Editing** | Alter real materials | Edited video clips, cropped screenshots |

---

## Information Operations Indicators

Signs you may be targeted by an influence operation:

### Volume Indicators
- Sudden spike in mentions or engagement
- Unusual number of new accounts engaging with you
- Coordinated posting (similar timing, language)

### Account Indicators
- New accounts with limited history
- Accounts with pattern names (FirstnameNumbers)
- Unusual follower/following ratios
- Profile inconsistencies

### Content Indicators
- Identical or near-identical messages
- Coordinated hashtags
- Cross-platform coordination
- Content faster than human reading/response speed

### Behavioral Indicators
- Off-hours activity (suggesting different time zones)
- Engagement without genuine interaction
- Amplification without comprehension

---

## Response Considerations

### When to Respond

| Factor | Respond | Don't Respond |
|--------|---------|---------------|
| **Audience** | Large, relevant audience seeing it | Small, irrelevant audience |
| **Narrative risk** | Silence could be seen as admission | Response would amplify attack |
| **Facts available** | Clear facts to counter | Complex, ambiguous situation |
| **Resources** | Capacity to sustain response | Would drain limited resources |

### Response Principles

1. **Document first** - Screenshot everything before it changes
2. **Analyze before acting** - Understand what you're dealing with
3. **Don't engage trolls** - Direct engagement often backfires
4. **One clear response** - If responding, do it once, clearly, factually
5. **Use your channels** - Respond through your platforms, not theirs
6. **Coordinate** - Work with allies, platforms, fact-checkers as appropriate
7. **Monitor** - Track the campaign's evolution

### Platform Actions

| Platform | Reporting Options |
|----------|------------------|
| Twitter/X | Report for coordinated inauthentic behavior, impersonation |
| Facebook | Report fake accounts, coordinated attacks |
| YouTube | Report for harassment, impersonation |
| Google | Report for search manipulation |
| Domain Registrars | Report impersonation sites |

---

## Monitoring for Information Operations

### What to Monitor

- Organization name and variations
- Staff names (especially leadership)
- Campaign names and hashtags
- Misspellings and variations
- Related issues and keywords

### Tools

| Tool | Use |
|------|-----|
| Google Alerts | Free monitoring for mentions |
| Social media native search | Platform-specific monitoring |
| CrowdTangle (if available) | Facebook/Instagram monitoring |
| Mention, Brandwatch, etc. | Paid comprehensive monitoring |

---

## Resources

- DISARM Foundation: https://www.disarm.foundation/
- DISARM Navigator: https://disarmfoundation.github.io/disarm-navigator/
- DISARM GitHub: https://github.com/DISARMFoundation/DISARMframeworks
- European Digital Media Observatory (EDMO): https://edmo.eu/
